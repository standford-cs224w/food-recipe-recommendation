{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GraphSAGE-based GNN Model for Food Recipe Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aref/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.loader import LinkNeighborLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph dataset loading\n",
    "\n",
    "In this step, we load the graphs already generated in the graph dataset generation step.    \n",
    "Since generating graph datasets is time consiming, we won't add them to each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3139285/1068171390.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=226570 },\n",
       "  recipe={ x=[231637, 3081] },\n",
       "  (user, rates, recipe)={\n",
       "    edge_index=[2, 770011],\n",
       "    edge_label=[192502, 1],\n",
       "    edge_label_index=[2, 192502],\n",
       "  },\n",
       "  (recipe, rev_rates, user)={ edge_index=[2, 770011] }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_graph(file_path):\n",
    "    return torch.load(file_path)\n",
    "\n",
    "dataset_version = 1\n",
    "base_data_path = f\"../data/graph/v{dataset_version}\"\n",
    "\n",
    "train_data = load_graph(f\"{base_data_path}/train_graph.pt\")\n",
    "val_data = load_graph(f\"{base_data_path}/validation_graph.pt\")\n",
    "# test_graph = load_graph(f\"{base_data_path}/test_graph.pt\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=226570 },\n",
       "  recipe={ x=[231637, 3081] },\n",
       "  (user, rates, recipe)={\n",
       "    edge_index=[2, 962513],\n",
       "    edge_label=[56618, 1],\n",
       "    edge_label_index=[2, 56618],\n",
       "  },\n",
       "  (recipe, rev_rates, user)={ edge_index=[2, 962513] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3106,    317,  16543,  ...,    541, 208023,    489],\n",
       "        [211809,   6600, 109688,  ...,  62108,  96459, 200804]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['user', 'rates', 'recipe'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['user', 'recipe'],\n",
       " [('user', 'rates', 'recipe'), ('recipe', 'rev_rates', 'user')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation\n",
    "\n",
    "### Model Architecture Overview\n",
    "This GNN model is designed for edge rating prediction in a recipe recommendation system. It uses the GraphSAGE architecture to encode node features into embeddings and a custom edge decoder to predict ratings between user and recipe nodes. The model consists of three main components: the encoder, the decoder, and the integration of both into a complete model for training and inference.\n",
    "\n",
    "### GNNEncoder Class\n",
    "**Purpose**: Encodes node features into embeddings using the GraphSAGE architecture.\n",
    "\n",
    "**Structure**:\n",
    "- `conv1`: First SAGE convolutional layer for initial feature transformation.\n",
    "- `conv2`: Second SAGE convolutional layer for output embedding generation.\n",
    "\n",
    "**Forward Pass**:\n",
    "- Takes node features `x` and edge connections `edge_index` as input.\n",
    "- Applies `conv1` followed by a ReLU activation.\n",
    "- Applies `conv2` to output the final node embeddings.\n",
    "\n",
    "### EdgeDecoder Class\n",
    "**Purpose**: Decodes the node embeddings to predict edge labels, such as ratings between users and recipes.\n",
    "\n",
    "**Structure**:\n",
    "- `lin1`: A fully connected layer that combines node embeddings from both ends of an edge.\n",
    "- `lin2`: A linear layer that outputs a scalar representing the predicted edge label (e.g., a rating).\n",
    "\n",
    "**Forward Pass**:\n",
    "- Extracts embeddings for connected nodes (e.g., user and recipe).\n",
    "- Concatenates these embeddings and passes them through `lin1` with a ReLU activation.\n",
    "- Outputs a single value through `lin2` representing the predicted edge rating.\n",
    "\n",
    "### Model Class\n",
    "**Purpose**: Integrates the encoder and decoder to create a complete GNN model.\n",
    "\n",
    "**Structure**:\n",
    "- `encoder`: Instantiates the `GNNEncoder` and adapts it to heterogeneous graphs using `to_hetero`, allowing the model to handle different types of nodes and edges.\n",
    "- `decoder`: A custom `EdgeDecoder` for predicting edge labels based on embeddings.\n",
    "\n",
    "**Forward Pass**:\n",
    "- Accepts a dictionary of node features `x_dict`, an edge index dictionary `edge_index_dict`, and the edge label index `edge_label_index`.\n",
    "- Passes `x_dict` and `edge_index_dict` to the encoder to generate node embeddings.\n",
    "- Uses the `decoder` to predict edge labels from these embeddings.\n",
    "\n",
    "**Execution Context**:\n",
    "- The model is set to run on a GPU if available, with `hidden_channels` set to 32 for embedding dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (user_embedding): Embedding(226570, 32)\n",
       "  (encoder): GraphModule(\n",
       "    (conv1): ModuleDict(\n",
       "      (user__rates__recipe): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "      (recipe__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "    )\n",
       "    (conv2): ModuleDict(\n",
       "      (user__rates__recipe): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "      (recipe__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (decoder): EdgeDecoder(\n",
       "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # print(f\"x: {x}\")\n",
    "        # print(f\"edge_index: {edge_index}\")\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['recipe'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_users):\n",
    "        super().__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, hidden_channels)\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, train_data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        # Initialize user features with embeddings\n",
    "        x_dict['user'] = self.user_embedding.weight\n",
    "\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_users = train_data['user']['num_nodes']\n",
    "\n",
    "model = Model(hidden_channels=32, num_users=num_users).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "In this step, we train the Graph Neural Network (GNN) model to optimize for the edge rating prediction task, where we predict ratings from users to recipes.\n",
    "\n",
    "### Mini-Batching\n",
    "Since our graph dataset is very large, we need to perform mini-batching to manage memory and computational resources effectively.\n",
    "Using PyG’s `LinkNeighborLoader`, we divide the data into smaller, manageable batches, allowing the model to process subsets of the graph at each step.  \n",
    "This loader samples neighboring nodes and edges for each target edge in the batch, focusing on the local neighborhood of each user-recipe interaction. This enables the model to capture relevant context without requiring the full graph in memory, making it ideal for efficient training with large datasets.\n",
    "\n",
    "### Model Optimization\n",
    "- **Optimizer**: We use `torch.optim.Adam` to adjust the model's parameters during training. The Adam optimizer effectively handles sparse gradients, helping the GNN learn efficiently from the graph data. The learning rate is set to 0.01 but can be modified during model tuning.\n",
    "\n",
    "- **Loss Function**: Mean Squared Error (MSE) loss measures the difference between predicted and actual ratings. Given the continuous nature of ratings, MSE is a suitable choice for our link regression task and is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{MSE Loss} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "  $$\n",
    "\n",
    "  where $y_i$ is the true rating, $\\hat{y}_i$ is the predicted rating, and $N$ is the number of samples.\n",
    "\n",
    "\n",
    "### Training Process\n",
    "For each epoch, we perform the following steps:\n",
    "  - **Batch Sampling**: The `train_loader` samples mini-batches of edges, allowing the model to focus on manageable portions of the data.\n",
    "  - **Prediction and Loss Calculation**: The model predicts ratings for each mini-batch and calculates the Mean Squared Error (MSE) loss against actual ratings.\n",
    "  - **Backpropagation and Parameter Update**: The optimizer updates the model’s parameters to minimize the loss.\n",
    "\n",
    "\n",
    "### Validation\n",
    "After each epoch, we also evaluate the model perfomance on validation set to ensure it generalizes well.\n",
    "Although MSE is used for training because of its efficient gradient properties, we use **Root Mean Squared Error (RMSE)** for evaluation since it provides error values in the same units as the target variable, making it more interpretable when assessing model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aref/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinkNeighborLoader()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_link_neighbor_loader(data, edge_type, batch_size=1024, num_neighbors=[10, 10], shuffle=True, num_workers=4):\n",
    "    \"\"\"\n",
    "    Creates a LinkNeighborLoader for the specified edge type in a HeteroData object.\n",
    "\n",
    "    Parameters:\n",
    "    - data (HeteroData): The heterogeneous graph data.\n",
    "    - edge_type (tuple): The edge type for which to create the loader, e.g., ('user', 'rates', 'recipe').\n",
    "    - batch_size (int): Number of edges to include in each batch.\n",
    "    - num_neighbors (list): Number of neighbors to sample at each layer.\n",
    "    - shuffle (bool): Whether to shuffle the data.\n",
    "    - num_workers (int): Number of subprocesses to use for data loading.\n",
    "\n",
    "    Returns:\n",
    "    - loader (LinkNeighborLoader): The data loader for the specified edge type.\n",
    "    \"\"\"\n",
    "    # Ensure the edge_type exists in the data\n",
    "    if edge_type not in data.edge_types:\n",
    "        raise ValueError(f\"Edge type {edge_type} not found in the data.\")\n",
    "\n",
    "    # Access the edge_label_index and edge_label for the specified edge type\n",
    "    edge_label_index = data[edge_type].get('edge_label_index', data[edge_type].edge_index)\n",
    "    edge_label = data[edge_type].get('edge_label', None)\n",
    "\n",
    "    # Create the LinkNeighborLoader\n",
    "    loader = LinkNeighborLoader(\n",
    "        data=data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        edge_label_index=(edge_type, edge_label_index),\n",
    "        edge_label=edge_label,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "# Define the edge type of interest\n",
    "edge_type = ('user', 'rates', 'recipe')\n",
    "\n",
    "# Create the training data loader\n",
    "train_loader = create_link_neighbor_loader(\n",
    "    data=train_data,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=1024,  # Adjust based on your GPU memory capacity\n",
    "    num_neighbors=[10, 10],  # Number of neighbors to sample at each layer\n",
    "    shuffle=True,  # Shuffle during training\n",
    "    num_workers=4  # Adjust based on your system\n",
    ")\n",
    "\n",
    "# Create the validation data loader\n",
    "validation_loader = create_link_neighbor_loader(\n",
    "    data=val_data,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=1024,  # Same as training\n",
    "    num_neighbors=[10, 10],  # Same as training\n",
    "    shuffle=False,  # No need to shuffle during validation\n",
    "    num_workers=4  # Adjust based on your system\n",
    ")\n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 664013962.6901, Train RMSE: 4.1559, Val RMSE: 4.1458\n",
      "Epoch: 002, Loss: 45404.5548, Train RMSE: 1.5144, Val RMSE: 1.5084\n",
      "Epoch: 003, Loss: 2.6491, Train RMSE: 1.4118, Val RMSE: 1.4216\n",
      "Epoch: 004, Loss: 2.1862, Train RMSE: 1.3855, Val RMSE: 1.3853\n",
      "Epoch: 005, Loss: 2.0773, Train RMSE: 1.4049, Val RMSE: 1.4063\n",
      "Epoch: 006, Loss: 2.1642, Train RMSE: 1.3710, Val RMSE: 1.3686\n",
      "Epoch: 007, Loss: 2.0484, Train RMSE: 1.7870, Val RMSE: 1.7787\n",
      "Epoch: 008, Loss: 2.2857, Train RMSE: 1.3196, Val RMSE: 1.3240\n",
      "Epoch: 009, Loss: 1.7969, Train RMSE: 1.3078, Val RMSE: 1.3110\n",
      "Epoch: 010, Loss: 1.7569, Train RMSE: 1.2921, Val RMSE: 1.2978\n",
      "Epoch: 011, Loss: 1.7577, Train RMSE: 1.3083, Val RMSE: 1.3109\n",
      "Epoch: 012, Loss: 1.7161, Train RMSE: 1.2879, Val RMSE: 1.2967\n",
      "Epoch: 013, Loss: 1.8159, Train RMSE: 1.2942, Val RMSE: 1.3002\n",
      "Epoch: 014, Loss: 1.6900, Train RMSE: 1.2763, Val RMSE: 1.2829\n",
      "Epoch: 015, Loss: 1.6682, Train RMSE: 1.2718, Val RMSE: 1.2767\n",
      "Epoch: 016, Loss: 1.6558, Train RMSE: 1.2766, Val RMSE: 1.2862\n",
      "Epoch: 017, Loss: 1.7413, Train RMSE: 1.2701, Val RMSE: 1.2780\n",
      "Epoch: 018, Loss: 1.6402, Train RMSE: 1.2671, Val RMSE: 1.2712\n",
      "Epoch: 019, Loss: 1.8478, Train RMSE: 1.2800, Val RMSE: 1.2863\n",
      "Epoch: 020, Loss: 1.6884, Train RMSE: 1.2655, Val RMSE: 1.2764\n",
      "Epoch: 021, Loss: 1.6172, Train RMSE: 1.2631, Val RMSE: 1.2718\n",
      "Epoch: 022, Loss: 1.6642, Train RMSE: 1.2779, Val RMSE: 1.2876\n",
      "Epoch: 023, Loss: 1.6111, Train RMSE: 1.2604, Val RMSE: 1.2694\n",
      "Epoch: 024, Loss: 1.5946, Train RMSE: 1.2570, Val RMSE: 1.2697\n",
      "Epoch: 025, Loss: 1.8254, Train RMSE: 1.3500, Val RMSE: 1.3537\n",
      "Epoch: 026, Loss: 1.6224, Train RMSE: 1.2634, Val RMSE: 1.2713\n",
      "Epoch: 027, Loss: 1.5987, Train RMSE: 1.2562, Val RMSE: 1.2647\n",
      "Epoch: 028, Loss: 1.5893, Train RMSE: 1.2571, Val RMSE: 1.2632\n",
      "Epoch: 029, Loss: 1.6190, Train RMSE: 1.2579, Val RMSE: 1.2620\n",
      "Epoch: 030, Loss: 1.5783, Train RMSE: 1.2471, Val RMSE: 1.2528\n",
      "Epoch: 031, Loss: 1.7697, Train RMSE: 1.2630, Val RMSE: 1.2715\n",
      "Epoch: 032, Loss: 1.6611, Train RMSE: 1.2520, Val RMSE: 1.2623\n",
      "Epoch: 033, Loss: 1.5841, Train RMSE: 1.2555, Val RMSE: 1.2600\n",
      "Epoch: 034, Loss: 1.6101, Train RMSE: 1.2583, Val RMSE: 1.2696\n",
      "Epoch: 035, Loss: 1.6236, Train RMSE: 1.2455, Val RMSE: 1.2528\n",
      "Epoch: 036, Loss: 1.5610, Train RMSE: 1.2398, Val RMSE: 1.2484\n",
      "Epoch: 037, Loss: 1.5541, Train RMSE: 1.2374, Val RMSE: 1.2458\n",
      "Epoch: 038, Loss: 1.5615, Train RMSE: 1.2424, Val RMSE: 1.2493\n",
      "Epoch: 039, Loss: 1.5419, Train RMSE: 1.2372, Val RMSE: 1.2459\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'recipe'].edge_label_index)\n",
    "        target = batch['user', 'rates', 'recipe'].edge_label.float().view(-1)  # Flatten target to match pred\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * target.size(0)\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'recipe'].edge_label_index)\n",
    "        pred = pred.clamp(min=0, max=5)\n",
    "        target = batch['user', 'rates', 'recipe'].edge_label.float().view(-1)  # Flatten target to match pred\n",
    "        loss = F.mse_loss(pred, target, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "    rmse = (total_loss / len(loader.dataset)) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 50):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_loader)\n",
    "    val_rmse = test(validation_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train RMSE: {train_rmse:.4f}, Validation RMSE: {val_rmse:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
