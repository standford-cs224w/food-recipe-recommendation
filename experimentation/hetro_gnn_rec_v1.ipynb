{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Generic GNN Model Framework for Food Recipe Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import SAGEConv, GATv2Conv, LGConv, LayerNorm, BatchNorm, HeteroConv\n",
    "from torch_geometric.loader import LinkNeighborLoader, DataLoader, NodeLoader\n",
    "from torch_geometric.data import HeteroData, Dataset\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flush():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "flush()\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Dataset Retrieval\n",
    "\n",
    "In this step, we load the graphs already generated in the graph dataset generation step.  \n",
    "In order to generate the graph dataset files, please follow the instruction on README.md. Since generating graph datasets is time consiming, we won't add them to each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287011/2149098207.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=226570 },\n",
       "  recipe={ x=[231637, 3081] },\n",
       "  (user, rates, recipe)={\n",
       "    edge_index=[2, 770011],\n",
       "    edge_label=[192502, 1],\n",
       "    edge_label_index=[2, 192502],\n",
       "  },\n",
       "  (recipe, rev_rates, user)={ edge_index=[2, 770011] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_graph(file_path):\n",
    "    return torch.load(file_path)\n",
    "\n",
    "dataset_version = 1\n",
    "base_data_path = f\"../data/graph/v{dataset_version}\"\n",
    "\n",
    "train_graph = load_graph(f\"{base_data_path}/train_graph.pt\")\n",
    "val_graph = load_graph(f\"{base_data_path}/validation_graph.pt\")\n",
    "test_graph = load_graph(f\"{base_data_path}/test_graph.pt\")\n",
    "\n",
    "train_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graph information: \n",
      "Number of nodes: 458207\n",
      "Number of edges: 1540022\n",
      "Metadata: (['user', 'recipe'], [('user', 'rates', 'recipe'), ('recipe', 'rev_rates', 'user')])\n",
      "Edge index: tensor([[  3106,    317,  16543,  ...,    541, 208023,    489],\n",
      "        [211809,   6600, 109688,  ...,  62108,  96459, 200804]])\n",
      "Recipe node_embeddings dimension:  3081\n",
      "Type of ('user', 'rates', 'recipe') edge index torch.int64\n",
      "Type of ('user', 'rates', 'recipe') edge index:  torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train graph information: \")\n",
    "print(\"Number of nodes:\", train_graph.num_nodes)\n",
    "print(\"Number of edges:\", train_graph.num_edges)\n",
    "print(\"Metadata:\", train_graph.metadata())\n",
    "print(\"Edge index:\", train_graph['user', 'rates', 'recipe'].edge_index)\n",
    "print(\"Recipe node_embeddings dimension: \", train_graph['recipe'].x.size(1))\n",
    "print(\"Type of ('user', 'rates', 'recipe') edge index\", train_graph[('user', 'rates', 'recipe')].edge_index.dtype)  \n",
    "print(\"Type of ('user', 'rates', 'recipe') edge index: \", train_graph[('user', 'rates', 'recipe')].edge_label_index.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between Training and Validation: 0 edges\n",
      "Overlap between Training and Test: 0 edges\n"
     ]
    }
   ],
   "source": [
    "# Check for overlapping edges\n",
    "train_edges = set(zip(train_graph['user', 'rates', 'recipe'].edge_label_index[0].tolist(),\n",
    "                      train_graph['user', 'rates', 'recipe'].edge_label_index[1].tolist()))\n",
    "\n",
    "val_edges = set(zip(val_graph['user', 'rates', 'recipe'].edge_label_index[0].tolist(),\n",
    "                    val_graph['user', 'rates', 'recipe'].edge_label_index[1].tolist()))\n",
    "\n",
    "test_edges = set(zip(test_graph['user', 'rates', 'recipe'].edge_label_index[0].tolist(),\n",
    "                     test_graph['user', 'rates', 'recipe'].edge_label_index[1].tolist()))\n",
    "\n",
    "overlap_val = train_edges & val_edges\n",
    "overlap_test = train_edges & test_edges\n",
    "\n",
    "print(f\"Overlap between Training and Validation: {len(overlap_val)} edges\")\n",
    "print(f\"Overlap between Training and Test: {len(overlap_test)} edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import LGConv\n",
    "\n",
    "class LGConvWrapper(torch.nn.Module):\n",
    "    def __init__(self, lgconv):\n",
    "        super(LGConvWrapper, self).__init__()\n",
    "        self.lgconv = lgconv\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None, **kwargs):\n",
    "        # LGConv uses x, edge_index, and optional edge_weight\n",
    "        if isinstance(x, tuple):  # If HeteroConv passes (x_src, x_dst)\n",
    "            x = x[0]  # Use only x_src\n",
    "        return self.lgconv(x, edge_index, edge_weight)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GATv2Conv, HeteroConv\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, graph, model_type, hidden_channels, num_layers, dropout, l2_reg):\n",
    "        super(HeteroGNN, self).__init__()\n",
    "        self.model_type = model_type.lower()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "        # User node embeddings\n",
    "        user_node_count = graph['user'].num_nodes\n",
    "        self.user_emb = torch.nn.Embedding(user_node_count, self.hidden_channels)\n",
    "        torch.nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "\n",
    "        # Recipe Features\n",
    "        recipe_x_dim = graph['recipe'].x.size(-1)\n",
    "        self.recipe_norm = BatchNorm(recipe_x_dim, affine=True)\n",
    "        self.recipe_lin = torch.nn.Linear(recipe_x_dim, self.hidden_channels)\n",
    "        torch.nn.init.xavier_uniform_(self.recipe_lin.weight)\n",
    "\n",
    "        # Define Convolutional Layers and BatchNorms\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv_dict = {}\n",
    "            for edge_type in graph.edge_types:\n",
    "                if self.model_type == 'sage':\n",
    "                    conv_dict[edge_type] = SAGEConv((-1, -1), self.hidden_channels)\n",
    "                elif self.model_type == 'gat':\n",
    "                    conv_dict[edge_type] = GATv2Conv((-1, -1), self.hidden_channels, heads=4, concat=False)\n",
    "                elif self.model_type == 'lightgcn':\n",
    "                    conv_dict[edge_type] = LGConvWrapper(LGConv(normalize=True))\n",
    "                else:\n",
    "                    raise ValueError(\"model_type should be one of ['sage', 'gat', 'lightgcn']\")\n",
    "            self.convs.append(HeteroConv(conv_dict, aggr='mean'))\n",
    "\n",
    "            if self.model_type in ['sage', 'gat']:\n",
    "                self.batch_norms.append(BatchNorm(self.hidden_channels))\n",
    "            else:\n",
    "                self.batch_norms.append(torch.nn.Identity())  # No BatchNorm for LightGCN\n",
    "\n",
    "        # Dropout Layer\n",
    "        self.dropout_layer = torch.nn.Dropout(dropout) if dropout > 0 else None\n",
    "\n",
    "        # Prediction Layer (out_channels fixed to 1 for consistency)\n",
    "        if self.model_type in ['sage', 'gat']:\n",
    "            self.predict_mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.hidden_channels * 2, self.hidden_channels),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.hidden_channels, 1)  # Output fixed to 1\n",
    "            )\n",
    "        else:\n",
    "            self.predict_mlp = None\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # Replace user node features with node embeddings\n",
    "        x_dict['user'] = self.user_emb.weight  # [num_users, hidden_channels]\n",
    "        x_dict['recipe'] = self.recipe_norm(x_dict['recipe'])  # [num_recipes, recipe_x_dim]\n",
    "        x_dict['recipe'] = self.recipe_lin(x_dict['recipe'])  # [num_recipes, hidden_channels]\n",
    "\n",
    "        # Apply HeteroConv layers\n",
    "        for conv, bn in zip(self.convs, self.batch_norms):\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            if self.model_type in ['sage', 'gat']:\n",
    "                # Apply BatchNorm, Dropout, and Activation only for GraphSAGE and GAT\n",
    "                x_dict = {key: bn(x) for key, x in x_dict.items()}\n",
    "                if self.dropout_layer:\n",
    "                    x_dict = {key: self.dropout_layer(x) for key, x in x_dict.items()}\n",
    "                x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "            else:\n",
    "                # For LightGCN, no BatchNorm, Dropout, or Activation\n",
    "                pass\n",
    "\n",
    "        # Collect final node embeddings\n",
    "        out_dict = {\n",
    "            'user': x_dict['user'],     # [num_users, hidden_channels]\n",
    "            'recipe': x_dict['recipe']  # [num_recipes, hidden_channels]\n",
    "        }\n",
    "        return out_dict\n",
    "\n",
    "    def predict(self, user_emb, recipe_emb):\n",
    "        \"\"\"\n",
    "        Predict edge ratings between user embeddings and recipe embeddings.\n",
    "        Clamps the predictions between 0 and 5 for all model types.\n",
    "        Ensures consistent output shape across all models.\n",
    "        \"\"\"\n",
    "        if self.model_type == 'lightgcn':\n",
    "            # Inner product for LightGCN\n",
    "            pred = (user_emb * recipe_emb).sum(dim=-1, keepdim=True)  # [batch_size, 1]\n",
    "        else:\n",
    "            # MLP for GraphSAGE and GAT\n",
    "            combined = torch.cat([user_emb, recipe_emb], dim=-1)  # [batch_size, hidden_channels * 2]\n",
    "            pred = self.predict_mlp(combined)  # [batch_size, 1]\n",
    "\n",
    "        # Clamp predictions between 0 and 5\n",
    "        pred = pred.clamp(min=0, max=5)\n",
    "        return pred\n",
    "\n",
    "    def loss_l2_regularization(self):\n",
    "        \"\"\"\n",
    "        Computes L2 regularization loss for model parameters.\n",
    "        \"\"\"\n",
    "        l2_loss = torch.sum(self.user_emb.weight**2)\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and param.requires_grad:\n",
    "                l2_loss += torch.sum(param**2)\n",
    "        return self.l2_reg * l2_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroGNN(\n",
      "  (user_emb): Embedding(226570, 128)\n",
      "  (recipe_norm): BatchNorm(3081, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (recipe_lin): Linear(in_features=3081, out_features=128, bias=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-2): 3 x HeteroConv(num_relations=2)\n",
      "  )\n",
      "  (batch_norms): ModuleList(\n",
      "    (0-2): 3 x Identity()\n",
      "  )\n",
      "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aref/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGConvWrapper.forward() missing 1 required positional argument: 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 196\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m train_mse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Evaluation phase\u001b[39;00m\n\u001b[1;32m    199\u001b[0m val_mse \u001b[38;5;241m=\u001b[39m evaluate_mse(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39marange(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_nodes, device\u001b[38;5;241m=\u001b[39mdevice),\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     26\u001b[0m }\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m out_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Extract edge information\u001b[39;00m\n\u001b[1;32m     32\u001b[0m edge \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrates\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 95\u001b[0m, in \u001b[0;36mHeteroGNN.forward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Apply HeteroConv layers\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv, bn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norms):\n\u001b[0;32m---> 95\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgat\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m# Apply BatchNorm, Dropout, and Activation only for GraphSAGE and GAT\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: bn(x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[1;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: LGConvWrapper.forward() missing 1 required positional argument: 'edge_index'"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch and computes training MSE.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The GNN model.\n",
    "    - loader (LinkNeighborLoader): Data loader for training.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
    "    - device (torch.device): Device to run computations on.\n",
    "\n",
    "    Returns:\n",
    "    - average_mse (float): Average MSE over the training set.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\", unit=\"batch\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Prepare node features\n",
    "        x_dict = {\n",
    "            'user': torch.arange(batch['user'].num_nodes, device=device),\n",
    "            'recipe': batch['recipe'].x\n",
    "        }\n",
    "\n",
    "        # Forward pass\n",
    "        out_dict = model(x_dict, batch.edge_index_dict)\n",
    "\n",
    "        # Extract edge information\n",
    "        edge = batch['user', 'rates', 'recipe']\n",
    "        user_emb = out_dict['user'][edge.edge_label_index[0]]\n",
    "        recipe_emb = out_dict['recipe'][edge.edge_label_index[1]]\n",
    "\n",
    "        # Prediction and target\n",
    "        pred = model.predict(user_emb, recipe_emb)  # [batch_size, 1]\n",
    "        target = edge.edge_label.float().view_as(pred)  # [batch_size, 1]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(pred, target) + model.loss_l2_regularization()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate MSE\n",
    "        mse_sum += F.mse_loss(pred, target, reduction='sum').item()\n",
    "        count += target.size(0)\n",
    "\n",
    "    average_mse = mse_sum / count\n",
    "    return average_mse\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mse(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given data loader and computes MSE.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The GNN model.\n",
    "    - loader (LinkNeighborLoader): Data loader for evaluation.\n",
    "    - device (torch.device): Device to run computations on.\n",
    "\n",
    "    Returns:\n",
    "    - average_mse (float): Average MSE over the evaluation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\", unit=\"batch\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Prepare node features\n",
    "        x_dict = {\n",
    "            'user': torch.arange(batch['user'].num_nodes, device=device),\n",
    "            'recipe': batch['recipe'].x\n",
    "        }\n",
    "\n",
    "        # Forward pass\n",
    "        out_dict = model(x_dict, batch.edge_index_dict)\n",
    "\n",
    "        # Extract edge information\n",
    "        edge = batch['user', 'rates', 'recipe']\n",
    "        user_emb = out_dict['user'][edge.edge_label_index[0]]\n",
    "        recipe_emb = out_dict['recipe'][edge.edge_label_index[1]]\n",
    "\n",
    "        # Prediction and target\n",
    "        pred = model.predict(user_emb, recipe_emb)  # [batch_size, 1]\n",
    "        target = edge.edge_label.float().view_as(pred)  # [batch_size, 1]\n",
    "\n",
    "        # Accumulate MSE\n",
    "        mse_sum += F.mse_loss(pred, target, reduction='sum').item()\n",
    "        count += target.size(0)\n",
    "\n",
    "    average_mse = mse_sum / count\n",
    "    return average_mse\n",
    "\n",
    "\n",
    "def create_link_neighbor_loader(data, edge_type, batch_size, num_neighbors, shuffle, num_workers):\n",
    "    \"\"\"\n",
    "    Creates a LinkNeighborLoader for the specified edge type.\n",
    "\n",
    "    Parameters:\n",
    "    - data (HeteroData): The input graph data.\n",
    "    - edge_type (tuple): The edge type for link prediction (e.g., ('user', 'rates', 'recipe')).\n",
    "    - batch_size (int): Number of samples per batch.\n",
    "    - num_neighbors (list): Number of neighbors to sample for each layer.\n",
    "    - shuffle (bool): Whether to shuffle the data.\n",
    "    - num_workers (int): Number of subprocesses for data loading.\n",
    "\n",
    "    Returns:\n",
    "    - LinkNeighborLoader: Configured data loader.\n",
    "    \"\"\"\n",
    "    edge_label_index = data[edge_type].edge_label_index\n",
    "    edge_label = data[edge_type].edge_label\n",
    "\n",
    "    loader = LinkNeighborLoader(\n",
    "        data=data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        edge_label_index=(edge_type, edge_label_index),\n",
    "        edge_label=edge_label,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming LGConvWrapper, HeteroGNN, train_epoch, evaluate_mse, and create_link_neighbor_loader are defined as above\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model configuration\n",
    "model_type = 'lightgcn'  # Options: 'sage', 'gat', 'lightgcn'\n",
    "hidden_channels = 128\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "l2_reg = 1e-5\n",
    "\n",
    "# Initialize the model with the entire train_graph.\n",
    "model = HeteroGNN(\n",
    "    graph=train_graph, \n",
    "    model_type=model_type,\n",
    "    hidden_channels=hidden_channels, \n",
    "    num_layers=num_layers, \n",
    "    dropout=dropout,\n",
    "    l2_reg=l2_reg\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define edge type for link prediction\n",
    "edge_type = ('user', 'rates', 'recipe')\n",
    "batch_size = 512  # Adjust based on your GPU memory\n",
    "num_neighbors = [10] + [5] * (num_layers - 1)\n",
    "num_workers = 3\n",
    "\n",
    "# Create loaders\n",
    "train_loader = create_link_neighbor_loader(\n",
    "    data=train_graph,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=batch_size,\n",
    "    num_neighbors=num_neighbors,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_loader = create_link_neighbor_loader(\n",
    "    data=val_graph,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=batch_size,\n",
    "    num_neighbors=num_neighbors,\n",
    "    shuffle=False,        # No need to shuffle for evaluation\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "best_val_mse = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch:02d}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    train_mse = train_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "    # Evaluation phase\n",
    "    val_mse = evaluate_mse(model, val_loader, device)\n",
    "\n",
    "    # Scheduler step based on validation MSE\n",
    "    scheduler.step(val_mse)\n",
    "\n",
    "    # Checkpointing\n",
    "    if val_mse < best_val_mse:\n",
    "        best_val_mse = val_mse\n",
    "        torch.save(model.state_dict(), 'best_hetero_gnn.pth')\n",
    "        print(f\"New best model saved with Validation MSE: {val_mse:.4f}\")\n",
    "\n",
    "    print(f\"Train MSE: {train_mse:.4f}, Validation MSE: {val_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Finally, we evaluate the performance of our model on the validation and test graphs using the **Root Mean Squared Error (RMSE)** and **@Recall@k** metrics. \n",
    "Although MSE is used as a loss function for training due to its efficient gradient properties, we use RMSE for evaluation because it provides error values in the same units as the target variable, making it more interpretable when assessing model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m\n\u001b[1;32m     33\u001b[0m         node_embeddings_dict[node_type] \u001b[38;5;241m=\u001b[39m out_dict[node_type]\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_embeddings_dict\n\u001b[1;32m     38\u001b[0m node_embeddings \u001b[38;5;241m=\u001b[39m get_all_node_embeddings(\n\u001b[0;32m---> 39\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[1;32m     40\u001b[0m     data\u001b[38;5;241m=\u001b[39mtrain_graph,  \u001b[38;5;66;03m# Ensure 'train_graph' includes all nodes\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     42\u001b[0m     node_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m node_embeddings\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_node_embeddings(model, data, device, node_types=['user', 'recipe']):\n",
    "    \"\"\"\n",
    "    Computes node_embeddings for all specified node types using a full forward pass.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The trained GNN model.\n",
    "    - data (HeteroData): The entire graph data.\n",
    "    - device (torch.device): The device to perform computations on.\n",
    "    - node_types (list): List of node types to compute node_embeddings for.\n",
    "\n",
    "    Returns:\n",
    "    - node_embeddings_dict (dict): Dictionary mapping node types to their embeddings.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Prepare node features\n",
    "        x_dict = {}\n",
    "        for node_type in node_types:\n",
    "            if node_type == 'user':\n",
    "                # Use node indices as placeholders; model will replace them with embeddings\n",
    "                x_dict[node_type] = torch.arange(data[node_type].num_nodes, device=device)\n",
    "            else:\n",
    "                # Use actual features for other node types\n",
    "                x_dict[node_type] = data[node_type].x.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out_dict = model(x_dict, data.edge_index_dict)\n",
    "\n",
    "    node_embeddings_dict = {}\n",
    "    for node_type in node_types:\n",
    "        node_embeddings_dict[node_type] = out_dict[node_type]\n",
    "\n",
    "    return node_embeddings_dict\n",
    "\n",
    "\n",
    "node_embeddings = get_all_node_embeddings(\n",
    "    model=model,\n",
    "    data=train_graph,  # Ensure 'train_graph' includes all nodes\n",
    "    device=device,\n",
    "    node_types=['user', 'recipe']\n",
    ")\n",
    "\n",
    "node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_by_rmse(model, data_loader, node_embeddings, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_edges = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, desc='Evaluating RMSE', leave=False):\n",
    "        edge_type = ('user', 'rates', 'recipe')  # Adjust if your edge type differs\n",
    "        edge_label_index = batch[edge_type].edge_label_index.to(device)  # [2, E]\n",
    "        edge_label = batch[edge_type].edge_label.to(device).view(-1)  # [E]\n",
    "\n",
    "        users = edge_label_index[0]    # [E]\n",
    "        recipes = edge_label_index[1]  # [E]\n",
    "\n",
    "        user_emb = node_embeddings['user'][users]        # [E, hidden_dim]\n",
    "        recipe_emb = node_embeddings['recipe'][recipes]  # [E, hidden_dim]\n",
    "\n",
    "        # Generate predictions\n",
    "        pred = model.predict(user_emb, recipe_emb).squeeze()\n",
    "        pred = pred.clamp(min=0, max=5)  # Clamp predictions\n",
    "\n",
    "        # Compute MSE\n",
    "        mse = F.mse_loss(pred, edge_label, reduction='sum').item()\n",
    "        total_loss += mse\n",
    "        total_edges += edge_label.size(0)\n",
    "\n",
    "    average_rmse = (total_loss / total_edges) ** 0.5\n",
    "    return average_rmse\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_by_recall_at_k(model, data_loader, node_embeddings, k, relevance_threshold, device):\n",
    "    model.eval()\n",
    "    user_predictions = defaultdict(list)\n",
    "    user_true_items = defaultdict(set)\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=f\"Evaluating Recall@{k}\", leave=False):\n",
    "        edge_type = ('user', 'rates', 'recipe')  # Adjust if your edge type differs\n",
    "        edge_label_index = batch[edge_type].edge_label_index.to(device)  # [2, E]\n",
    "        edge_label = batch[edge_type].edge_label.to(device).view(-1)  # [E]\n",
    "\n",
    "        users = edge_label_index[0]    # [E]\n",
    "        recipes = edge_label_index[1]  # [E]\n",
    "\n",
    "        user_emb = node_embeddings['user'][users]        # [E, hidden_dim]\n",
    "        recipe_emb = node_embeddings['recipe'][recipes]  # [E, hidden_dim]\n",
    "\n",
    "        # Generate predictions\n",
    "        pred = model.predict(user_emb, recipe_emb).squeeze()\n",
    "        pred = pred.clamp(min=0, max=5)  # Clamp predictions\n",
    "\n",
    "        # Populate user_predictions and user_true_items\n",
    "        for i, user_id in enumerate(users.cpu().numpy()):\n",
    "            user_predictions[user_id].append((pred[i].item(), recipes[i].item()))\n",
    "            if edge_label[i].item() >= relevance_threshold:\n",
    "                user_true_items[user_id].add(recipes[i].item())\n",
    "\n",
    "    recalls = []\n",
    "    for user_id in user_predictions:\n",
    "        # Sort predictions by score in descending order and get top-k items\n",
    "        sorted_predictions = sorted(user_predictions[user_id], key=lambda x: x[0], reverse=True)\n",
    "        topk_recipes = {item for _, item in sorted_predictions[:k]}\n",
    "        true_items = user_true_items[user_id]\n",
    "\n",
    "        if true_items:\n",
    "            recall = len(topk_recipes & true_items) / len(true_items)\n",
    "            recalls.append(recall)\n",
    "\n",
    "    recall_at_k = sum(recalls) / len(recalls) if recalls else 0.0\n",
    "    return recall_at_k\n",
    "\n",
    "\n",
    "def create_link_neighbor_loader(data, edge_type, batch_size, num_neighbors, shuffle, num_workers):\n",
    "    if edge_type not in data.edge_types:\n",
    "        raise ValueError(f\"Edge type {edge_type} not found in the data.\")\n",
    "\n",
    "    edge_label_index = data[edge_type].edge_label_index\n",
    "    edge_label = data[edge_type].edge_label\n",
    "\n",
    "    loader = LinkNeighborLoader(\n",
    "        data=data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        edge_label_index=(edge_type, edge_label_index),\n",
    "        edge_label=edge_label,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "test_loader = create_link_neighbor_loader(\n",
    "    data=test_graph,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=batch_size,\n",
    "    num_neighbors=num_neighbors,\n",
    "    shuffle=False,        # No need to shuffle for evaluation\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# List of evaluation datasets and their corresponding loaders\n",
    "evaluation_sets = [\n",
    "    ('Validation', val_graph, val_loader),\n",
    "    ('Test', test_graph, test_loader)\n",
    "]\n",
    "\n",
    "# Define standalone variables for recall evaluation\n",
    "k = 5\n",
    "rating_threshold = 4 \n",
    "\n",
    "# Evaluation for Recall@K and RMSE\n",
    "for data_split, graph, loader in evaluation_sets:\n",
    "    # Compute RMSE.\n",
    "    rmse = evaluate_by_rmse(\n",
    "        model=model,\n",
    "        data_loader=loader,\n",
    "        node_embeddings=node_embeddings,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Compute Recall@K.\n",
    "    recall = evaluate_by_recall_at_k(\n",
    "        model=model,\n",
    "        data_loader=loader,\n",
    "        node_embeddings=node_embeddings,\n",
    "        k=k,\n",
    "        relevance_threshold=rating_threshold,\n",
    "        device=device\n",
    "    )\n",
    "        \n",
    "    print(f\"{data_split} set: RMSE = {rmse:.4f}, Recall@{k} = {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
