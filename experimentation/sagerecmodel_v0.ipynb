{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE-based Recommender Model (SageRecModel) for Food Recipe Recommendation (V0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aref/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.loader import LinkNeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flush():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "flush()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph dataset loading\n",
    "\n",
    "In this step, we load the graphs already generated in the graph dataset generation step.    \n",
    "Since generating graph datasets is time consiming, we won't add them to each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1297365/193544470.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=226570 },\n",
       "  recipe={ x=[231637, 3081] },\n",
       "  (user, rates, recipe)={\n",
       "    edge_index=[2, 770011],\n",
       "    edge_label=[192502, 1],\n",
       "    edge_label_index=[2, 192502],\n",
       "  },\n",
       "  (recipe, rev_rates, user)={ edge_index=[2, 770011] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_graph(file_path):\n",
    "    return torch.load(file_path)\n",
    "\n",
    "dataset_version = 1\n",
    "base_data_path = f\"../data/graph/v{dataset_version}\"\n",
    "\n",
    "train_graph = load_graph(f\"{base_data_path}/train_graph.pt\")\n",
    "validation_graph = load_graph(f\"{base_data_path}/validation_graph.pt\")\n",
    "test_graph = load_graph(f\"{base_data_path}/test_graph.pt\")\n",
    "\n",
    "train_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graph information: \n",
      "Numbder of nodes: 458207\n",
      "Numbder of edges: 1540022\n",
      "Metadata: (['user', 'recipe'], [('user', 'rates', 'recipe'), ('recipe', 'rev_rates', 'user')])\n",
      "Edge index: tensor([[  3106,    317,  16543,  ...,    541, 208023,    489],\n",
      "        [211809,   6600, 109688,  ...,  62108,  96459, 200804]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train graph information: \")\n",
    "print(\"Numbder of nodes:\", train_graph.num_nodes)\n",
    "print(\"Numbder of edges:\", train_graph.num_edges)\n",
    "print(\"Metadata:\", train_graph.metadata())\n",
    "print(\"Edge index:\", train_graph['user', 'rates', 'recipe'].edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation\n",
    "In this step, we implement a heterogeneous GNN model for the edge rating prediction task in a recipe recommendation system. \n",
    "Our model uses the GraphSAGE architecture to encode node features into embeddings and a custom edge decoder to predict ratings between user and recipe nodes. The model consists of three main components: the encoder, the decoder, and the integration of both into a complete model for training and inference.\n",
    "\n",
    "### GNNEncoder\n",
    "It encodes node features into embeddings using the GraphSAGE architecture.\n",
    "\n",
    "**Structure**:\n",
    "- `conv1`: First SAGE convolutional layer for initial feature transformation.\n",
    "- `conv2`: Second SAGE convolutional layer for output embedding generation.\n",
    "\n",
    "**Forward Pass**:\n",
    "- Takes node features `x` and edge connections `edge_index` as input.\n",
    "- Applies `conv1` followed by a ReLU activation.\n",
    "- Applies `conv2` to output the final node embeddings.\n",
    "\n",
    "### EdgeDecoder\n",
    "It acts a prediction head to predict edge labels (ratings) by by decoding the node embeddings\n",
    "\n",
    "**Structure**:\n",
    "- `lin1`: A fully connected layer that combines node embeddings from both ends of an edge.\n",
    "- `lin2`: A linear layer that outputs a scalar representing the predicted edge label (e.g., a rating).\n",
    "\n",
    "**Forward Pass**:\n",
    "- Extracts embeddings for connected nodes (e.g., user and recipe).\n",
    "- Concatenates these embeddings and passes them through `lin1` with a ReLU activation.\n",
    "- Outputs a single value through `lin2` representing the predicted edge rating.\n",
    "\n",
    "### SageRecModel\n",
    "It integrates the encoder and decoder to create a complete GNN model for edge rating prediction.\n",
    "\n",
    "**Structure**:\n",
    "- `Encoder`: Instantiates the `GNNEncoder` and adapts it to heterogeneous graphs using `to_hetero`, allowing the model to handle different types of nodes and edges.\n",
    "- `Decoder`: A custom `EdgeDecoder` for predicting edge labels based on embeddings.\n",
    "\n",
    "**User Embeddings**:\n",
    "Due to lack of user features, user embeddings are randomly initialized and then learned during training to capture user-specific patterns in interactions.\n",
    "\n",
    "**Forward Pass**:\n",
    "- Accepts a dictionary of node features `x_dict`, an edge index dictionary `edge_index_dict`, and the edge label index `edge_label_index`.\n",
    "- Passes `x_dict` and `edge_index_dict` to the encoder to generate node embeddings.\n",
    "- Uses the `decoder` to predict edge labels from these embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f7244129070>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SageRecModel(\n",
       "  (user_embedding): Embedding(226570, 32)\n",
       "  (encoder): GraphModule(\n",
       "    (conv1): ModuleDict(\n",
       "      (user__rates__recipe): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "      (recipe__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "    )\n",
       "    (conv2): ModuleDict(\n",
       "      (user__rates__recipe): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "      (recipe__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (decoder): EdgeDecoder(\n",
       "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # print(f\"x: {x}\")\n",
    "        # print(f\"edge_index: {edge_index}\")\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['recipe'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class SageRecModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_users):\n",
    "        super().__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, hidden_channels)\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, train_graph.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        # Initialize user features with embeddings\n",
    "        x_dict['user'] = self.user_embedding.weight\n",
    "\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "\n",
    "num_users = train_graph['user']['num_nodes']\n",
    "# Embedding dimension size.\n",
    "hidden_channels = 32\n",
    "model = SageRecModel(hidden_channels=hidden_channels, num_users=num_users).to(device)\n",
    "\n",
    "print(model.parameters())\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "In this step, we train the Graph Neural Network (GNN) model to optimize for the edge rating prediction task, where we predict ratings from users to recipes.\n",
    "\n",
    "### Mini-batching\n",
    "Since our graph dataset is very large, we need to perform mini-batching to manage memory and computational resources effectively.\n",
    "Using PyG’s `LinkNeighborLoader`, we divide the data into smaller, manageable batches, allowing the model to process subsets of the graph at each step.  \n",
    "This loader samples neighboring nodes and edges for each target edge in the batch, focusing on the local neighborhood of each user-recipe interaction. This enables the model to capture relevant context without requiring the full graph in memory, making it ideal for efficient training with large datasets.\n",
    "\n",
    "### Optimization\n",
    "- **Optimizer**: We use `torch.optim.Adam` to adjust the model's parameters during training. The Adam optimizer effectively handles sparse gradients, helping the GNN learn efficiently from the graph data. The learning rate is set to 0.01 but can be modified during model tuning.\n",
    "\n",
    "- **Loss Function**: Mean Squared Error (MSE) loss measures the difference between predicted and actual ratings. Given the continuous nature of ratings, MSE is a suitable choice for our link regression task and is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{MSE Loss} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "  $$\n",
    "\n",
    "  where $y_i$ is the true rating, $\\hat{y}_i$ is the predicted rating, and $N$ is the number of samples.\n",
    "\n",
    "\n",
    "### Training process\n",
    "For each epoch, we perform the following steps:\n",
    "  - **Batch sampling**: The `train_data_loader` samples mini-batches of edges, allowing the model to process manageable portions of the data.\n",
    "  - **Forward propagation**: The model predicts ratings for each mini-batch of edges and calculates the Mean Squared Error (MSE) loss between the predicted and actual ratings.\n",
    "  - **Backward propagation**: Calculates the gradients of the loss with respect to the model’s parameters, including embeddings.\n",
    "  - **Parameter update**: The optimizer uses these gradients to update the model’s parameters, refining the embeddings and other learnable parameters to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aref/ar_code/food-recipe-recommendation/venv/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "def create_link_neighbor_loader(data, edge_type, batch_size=1024, num_neighbors=[10, 10], shuffle=True, num_workers=4):\n",
    "    \"\"\"\n",
    "    Creates a LinkNeighborLoader for the specified edge type in a HeteroData object.\n",
    "\n",
    "    Parameters:\n",
    "    - data (HeteroData): The heterogeneous graph data.\n",
    "    - edge_type (tuple): The edge type for which to create the loader, e.g., ('user', 'rates', 'recipe').\n",
    "    - batch_size (int): Number of edges to include in each batch.\n",
    "    - num_neighbors (list): Number of neighbors to sample at each layer.\n",
    "    - shuffle (bool): Whether to shuffle the data.\n",
    "    - num_workers (int): Number of subprocesses to use for data loading.\n",
    "\n",
    "    Returns:\n",
    "    - loader (LinkNeighborLoader): The data loader for the specified edge type.\n",
    "    \"\"\"\n",
    "    # Ensure the edge_type exists in the data\n",
    "    if edge_type not in data.edge_types:\n",
    "        raise ValueError(f\"Edge type {edge_type} not found in the data.\")\n",
    "\n",
    "    # Access the edge_label_index and edge_label for the specified edge type\n",
    "    edge_label_index = data[edge_type].get('edge_label_index', data[edge_type].edge_index)\n",
    "    edge_label = data[edge_type].get('edge_label', None)\n",
    "\n",
    "    # Create the LinkNeighborLoader\n",
    "    loader = LinkNeighborLoader(\n",
    "        data=data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        edge_label_index=(edge_type, edge_label_index),\n",
    "        edge_label=edge_label,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "edge_type = ('user', 'rates', 'recipe') # Define the edge type of interest\n",
    "batch_size = 1024  # Adjust based on your GPU memory capacity\n",
    "num_neighbors = [10, 10] # Number of neighbors to sample at each layer\n",
    "num_workers = 4  # Adjust based on your system\n",
    "\n",
    "# Create the training data loader\n",
    "train_data_loader = create_link_neighbor_loader(\n",
    "    data=train_graph,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=batch_size, \n",
    "    num_neighbors=num_neighbors, \n",
    "    shuffle=True,\n",
    "    num_workers=num_workers \n",
    ")\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss (MSE): 326693619.3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss (MSE): 18353875.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss (MSE): 19401.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss (MSE): 31.8266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss (MSE): 23.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss (MSE): 20.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss (MSE): 19.7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss (MSE): 19.3548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss (MSE): 18.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss (MSE): 18.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss (MSE): 17.9090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss (MSE): 17.3473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss (MSE): 16.7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss (MSE): 1867.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss (MSE): 27.2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss (MSE): 3.7226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss (MSE): 3.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss (MSE): 2.8632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Loss (MSE): 3.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss (MSE): 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Loss (MSE): 5.4770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Loss (MSE): 1.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Loss (MSE): 1.8474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss (MSE): 1.8143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss (MSE): 2.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Loss (MSE): 2.1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Loss (MSE): 1.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Loss (MSE): 1.7336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Loss (MSE): 1.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Loss (MSE): 1.7048\n"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader, desc='Training', unit='batch', leave=False):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'recipe'].edge_label_index)\n",
    "        # Flatten target to match pred.\n",
    "        target = batch['user', 'rates', 'recipe'].edge_label.float().view(-1)\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * target.size(0)\n",
    "    \n",
    "    # Compute average loss (MSE) per data point (edge). \n",
    "    mse = total_loss / len(data_loader.dataset)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train(model, train_data_loader, optimizer)\n",
    "    print(f'Epoch: {epoch:03d}, Loss (MSE): {loss:.4f}')\n",
    "\n",
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Finally, we evaluate the perfomance of our model on the validation and test graphs using **Root Mean Squared Error (RMSE)** metric. \n",
    "Although MSE is used a lost function for training because of its efficient gradient properties, we use RMSE for evaluation since it provides error values in the same units as the target variable, making it more interpretable when assessing model performance.\n",
    "\n",
    "We also report the evalution result on train graph to monitor the model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_loader = create_link_neighbor_loader(\n",
    "    data=validation_graph,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=batch_size, \n",
    "    num_neighbors=num_neighbors, \n",
    "    shuffle=False, # No need to shuffle during validation\n",
    "    num_workers=num_workers \n",
    ")\n",
    "\n",
    "test_data_loader = create_link_neighbor_loader(\n",
    "    data=test_graph,\n",
    "    edge_type=edge_type,\n",
    "    batch_size=batch_size, \n",
    "    num_neighbors=num_neighbors, \n",
    "    shuffle=False, # No need to shuffle during testing\n",
    "    num_workers=num_workers \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1.2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 1.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.2842\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_by_rmse(data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader, desc='Evaluating', unit='batch', leave=False):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'recipe'].edge_label_index)\n",
    "        # min rating is 0 and max rating is 5.\n",
    "        pred = pred.clamp(min=0, max=5)\n",
    "        # Flatten target to match pred\n",
    "        target = batch['user', 'rates', 'recipe'].edge_label.float().view(-1)  \n",
    "        loss = F.mse_loss(pred, target, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    rmse = (total_loss / len(data_loader.dataset)) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "evluation_data_loaders = {\n",
    "    'Train': train_data_loader,\n",
    "    'Validation': validation_data_loader,\n",
    "    'Test': test_data_loader\n",
    "}\n",
    "evaluation_results = {}\n",
    "for data_split_name, data_loader in evluation_data_loaders.items():\n",
    "    evaluation_result = evaluate_by_rmse(data_loader)\n",
    "    print(f'{data_split_name} RMSE: {evaluation_result:.4f}')\n",
    "    flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
